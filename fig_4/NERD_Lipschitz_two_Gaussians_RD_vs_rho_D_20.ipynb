{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "answering-chance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from numpy import genfromtxt\n",
    "from aux_functions2 import xavier_init\n",
    "from aux_functions2 import plot #MINE\n",
    "\n",
    "import csv\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "boring-berlin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "5\n",
      "20\n",
      "4000\n",
      "150000\n"
     ]
    }
   ],
   "source": [
    "steps = 20000 # int(sys.argv[1])  # number of training steps\n",
    "iteration = 5 # int(sys.argv[2])  # number of iterations (iid runs)\n",
    "d = 20 # int(sys.argv[3])  # dimension of the distributions\n",
    "mb_size = 4000 # int(sys.argv[4])  # batch size\n",
    "N = 150000\n",
    "rho_range = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "lam_gp = 0.1  # gradient penalty constant: \\lambda_{gp}\n",
    "\n",
    "print(steps)\n",
    "print(iteration)\n",
    "print(d)\n",
    "print(mb_size)\n",
    "print(N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "upper-workshop",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tasos/Documents/GSRT_NeoiErevnites/jupyter_notebook/NOTEBOOKS/fig_4/aux_functions2.py:19: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters\n",
    "if d==4:\n",
    "    layers = [d, 8, 8, 4, 1]\n",
    "elif d==20:\n",
    "    layers = [d, 32, 32, 16, 1]\n",
    "elif d==50:\n",
    "    layers = [d, 32, 32, 16, 1] # [d, 64, 64, 32, 1]\n",
    "else:                      \n",
    "    print('check dimension!')\n",
    "\n",
    "lam = 1.0 # lambda=beta+gamma\n",
    "\n",
    "# initialize\n",
    "X = tf.placeholder(tf.float32, shape=[None, d])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, d])\n",
    "\n",
    "def initialize_NN(layers):\n",
    "    NN_W = []\n",
    "    NN_b = []\n",
    "    num_layers = len(layers)\n",
    "    for l in range(0,num_layers-1):\n",
    "        W = tf.Variable(xavier_init(size=[layers[l], layers[l+1]]), name=\"W\")\n",
    "        b = tf.Variable(tf.zeros([1,layers[l+1]], dtype=tf.float32), dtype=tf.float32)\n",
    "        NN_W.append(W)\n",
    "        NN_b.append(b)\n",
    "    return NN_W, NN_b\n",
    "\n",
    "D_W, D_b = initialize_NN(layers)\n",
    "\n",
    "theta_D = [D_W, D_b] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "southeast-diagnosis",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(x):\n",
    "    num_layers = len(D_W) + 1\n",
    "    \n",
    "    h = x  \n",
    "    for l in range(0,num_layers-2):\n",
    "        W = D_W[l]\n",
    "        b = D_b[l]\n",
    "        h = tf.tanh(tf.add(tf.matmul(h, W), b))\n",
    "    \n",
    "    W = D_W[-1]\n",
    "    b = D_b[-1]\n",
    "    #out = 50.0 * tf.nn.tanh(tf.add(tf.matmul(h, W), b) / 50.0) # bound M=50\n",
    "    #out = 20.0 * tf.nn.tanh(tf.add(tf.matmul(h, W), b) / 20.0)\n",
    "    out =  tf.add(tf.matmul(h, W), b)   # unbounded!\n",
    "\n",
    "    return out\n",
    "\n",
    "D_real = discriminator(X)\n",
    "D_fake = discriminator(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "objective-concert",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(device_count={'GPU': 0})\n",
    "sess = tf.Session(config=config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "SF = 1000\n",
    "D_loss_vals =  np.zeros(shape=(len(rho_range), iteration)) \n",
    "RD_exact_rho =  np.zeros(shape= len(rho_range))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "limiting-following",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j= 0\n",
      "rho= 0.1\n",
      "WARNING:tensorflow:From /home/tasos/Documents/GSRT_NeoiErevnites/tf1_env_py36/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Iteration: 0\n",
      "Iter: 0\n",
      "Renyi divergence: [1.9018771e-06]\n",
      "\n",
      "Iter: 1000\n",
      "Renyi divergence: [0.01703268]\n",
      "\n",
      "Iter: 2000\n",
      "Renyi divergence: [0.03493863]\n",
      "\n",
      "Iter: 3000\n",
      "Renyi divergence: [0.04876268]\n",
      "\n",
      "Iter: 4000\n",
      "Renyi divergence: [0.0474689]\n",
      "\n",
      "Iter: 5000\n",
      "Renyi divergence: [0.04921186]\n",
      "\n",
      "Iter: 6000\n",
      "Renyi divergence: [0.06999481]\n",
      "\n",
      "Iter: 7000\n",
      "Renyi divergence: [0.05673438]\n",
      "\n",
      "Iter: 8000\n",
      "Renyi divergence: [0.05445135]\n",
      "\n",
      "Iter: 9000\n",
      "Renyi divergence: [0.05150473]\n",
      "\n",
      "Iter: 10000\n",
      "Renyi divergence: [0.05494273]\n",
      "\n",
      "Iter: 11000\n",
      "Renyi divergence: [0.05852807]\n",
      "\n",
      "Iter: 12000\n",
      "Renyi divergence: [0.06486642]\n",
      "\n",
      "Iter: 13000\n",
      "Renyi divergence: [0.06653094]\n",
      "\n",
      "Iter: 14000\n",
      "Renyi divergence: [0.0421015]\n",
      "\n",
      "Iter: 15000\n",
      "Renyi divergence: [0.06147975]\n",
      "\n",
      "Iter: 16000\n",
      "Renyi divergence: [0.04650432]\n",
      "\n",
      "Iter: 17000\n",
      "Renyi divergence: [0.08008224]\n",
      "\n",
      "Iter: 18000\n",
      "Renyi divergence: [0.08226299]\n",
      "\n",
      "Iter: 19000\n",
      "Renyi divergence: [0.06085026]\n",
      "\n",
      "Iteration: 1\n",
      "Iter: 0\n",
      "Renyi divergence: [-7.707509e-06]\n",
      "\n",
      "Iter: 1000\n",
      "Renyi divergence: [0.02992463]\n",
      "\n",
      "Iter: 2000\n",
      "Renyi divergence: [0.04739809]\n",
      "\n",
      "Iter: 3000\n",
      "Renyi divergence: [0.06320453]\n",
      "\n",
      "Iter: 4000\n",
      "Renyi divergence: [0.05177581]\n",
      "\n",
      "Iter: 5000\n",
      "Renyi divergence: [0.05361509]\n",
      "\n",
      "Iter: 6000\n",
      "Renyi divergence: [0.04361379]\n",
      "\n",
      "Iter: 7000\n",
      "Renyi divergence: [0.04860091]\n",
      "\n",
      "Iter: 8000\n",
      "Renyi divergence: [0.04905462]\n",
      "\n",
      "Iter: 9000\n",
      "Renyi divergence: [0.05704808]\n",
      "\n",
      "Iter: 10000\n",
      "Renyi divergence: [0.04663217]\n",
      "\n",
      "Iter: 11000\n",
      "Renyi divergence: [0.06124377]\n",
      "\n",
      "Iter: 12000\n",
      "Renyi divergence: [0.05750036]\n",
      "\n",
      "Iter: 13000\n",
      "Renyi divergence: [0.06230223]\n",
      "\n",
      "Iter: 14000\n",
      "Renyi divergence: [0.0518837]\n",
      "\n",
      "Iter: 15000\n",
      "Renyi divergence: [0.0655576]\n",
      "\n",
      "Iter: 16000\n",
      "Renyi divergence: [0.06385374]\n",
      "\n",
      "Iter: 17000\n",
      "Renyi divergence: [0.07295394]\n",
      "\n",
      "Iter: 18000\n",
      "Renyi divergence: [0.05628002]\n",
      "\n",
      "Iter: 19000\n",
      "Renyi divergence: [0.0676229]\n",
      "\n",
      "Iteration: 2\n",
      "Iter: 0\n",
      "Renyi divergence: [1.0528718e-05]\n",
      "\n",
      "Iter: 1000\n",
      "Renyi divergence: [0.02625763]\n",
      "\n",
      "Iter: 2000\n",
      "Renyi divergence: [0.04081297]\n",
      "\n",
      "Iter: 3000\n",
      "Renyi divergence: [0.04366207]\n",
      "\n",
      "Iter: 4000\n",
      "Renyi divergence: [0.05822277]\n",
      "\n",
      "Iter: 5000\n",
      "Renyi divergence: [0.05760568]\n",
      "\n",
      "Iter: 6000\n",
      "Renyi divergence: [0.05167818]\n",
      "\n",
      "Iter: 7000\n",
      "Renyi divergence: [0.05086052]\n",
      "\n",
      "Iter: 8000\n",
      "Renyi divergence: [0.0508616]\n",
      "\n",
      "Iter: 9000\n",
      "Renyi divergence: [0.06255907]\n",
      "\n",
      "Iter: 10000\n",
      "Renyi divergence: [0.06303847]\n",
      "\n",
      "Iter: 11000\n",
      "Renyi divergence: [0.05763042]\n",
      "\n",
      "Iter: 12000\n",
      "Renyi divergence: [0.05917883]\n",
      "\n",
      "Iter: 13000\n",
      "Renyi divergence: [0.0535388]\n",
      "\n",
      "Iter: 14000\n",
      "Renyi divergence: [0.07343197]\n",
      "\n",
      "Iter: 15000\n",
      "Renyi divergence: [0.06089914]\n",
      "\n",
      "Iter: 16000\n",
      "Renyi divergence: [0.06281006]\n",
      "\n",
      "Iter: 17000\n",
      "Renyi divergence: [0.07188761]\n",
      "\n",
      "Iter: 18000\n",
      "Renyi divergence: [0.05717468]\n",
      "\n",
      "Iter: 19000\n",
      "Renyi divergence: [0.06042123]\n",
      "\n",
      "Iteration: 3\n",
      "Iter: 0\n",
      "Renyi divergence: [8.824631e-06]\n",
      "\n",
      "Iter: 1000\n",
      "Renyi divergence: [0.01626104]\n",
      "\n",
      "Iter: 2000\n",
      "Renyi divergence: [0.04466659]\n",
      "\n",
      "Iter: 3000\n",
      "Renyi divergence: [0.04781079]\n",
      "\n",
      "Iter: 4000\n",
      "Renyi divergence: [0.06239438]\n",
      "\n",
      "Iter: 5000\n",
      "Renyi divergence: [0.06357312]\n",
      "\n",
      "Iter: 6000\n",
      "Renyi divergence: [0.04993951]\n",
      "\n",
      "Iter: 7000\n",
      "Renyi divergence: [0.05915189]\n",
      "\n",
      "Iter: 8000\n",
      "Renyi divergence: [0.06057775]\n",
      "\n",
      "Iter: 9000\n",
      "Renyi divergence: [0.04777753]\n",
      "\n",
      "Iter: 10000\n",
      "Renyi divergence: [0.06090868]\n",
      "\n",
      "Iter: 11000\n",
      "Renyi divergence: [0.05337524]\n",
      "\n",
      "Iter: 12000\n",
      "Renyi divergence: [0.06341255]\n",
      "\n",
      "Iter: 13000\n",
      "Renyi divergence: [0.05368531]\n",
      "\n",
      "Iter: 14000\n",
      "Renyi divergence: [0.059412]\n",
      "\n",
      "Iter: 15000\n",
      "Renyi divergence: [0.05879629]\n",
      "\n",
      "Iter: 16000\n",
      "Renyi divergence: [0.06637478]\n",
      "\n",
      "Iter: 17000\n",
      "Renyi divergence: [0.07877445]\n",
      "\n",
      "Iter: 18000\n",
      "Renyi divergence: [0.07640076]\n",
      "\n",
      "Iter: 19000\n",
      "Renyi divergence: [0.07841206]\n",
      "\n",
      "Iteration: 4\n",
      "Iter: 0\n",
      "Renyi divergence: [-6.3686166e-06]\n",
      "\n",
      "Iter: 1000\n",
      "Renyi divergence: [0.03812832]\n",
      "\n",
      "Iter: 2000\n",
      "Renyi divergence: [0.05510974]\n",
      "\n",
      "Iter: 3000\n",
      "Renyi divergence: [0.04877365]\n",
      "\n",
      "Iter: 4000\n",
      "Renyi divergence: [0.05709893]\n",
      "\n",
      "Iter: 5000\n",
      "Renyi divergence: [0.05747163]\n",
      "\n",
      "Iter: 6000\n",
      "Renyi divergence: [0.05259353]\n",
      "\n",
      "Iter: 7000\n",
      "Renyi divergence: [0.05877554]\n",
      "\n",
      "Iter: 8000\n",
      "Renyi divergence: [0.0413686]\n",
      "\n",
      "Iter: 9000\n",
      "Renyi divergence: [0.05065238]\n",
      "\n",
      "Iter: 10000\n",
      "Renyi divergence: [0.06071699]\n",
      "\n",
      "Iter: 11000\n",
      "Renyi divergence: [0.04388988]\n",
      "\n",
      "Iter: 12000\n",
      "Renyi divergence: [0.0594238]\n",
      "\n",
      "Iter: 13000\n",
      "Renyi divergence: [0.05488712]\n",
      "\n",
      "Iter: 14000\n",
      "Renyi divergence: [0.04531407]\n",
      "\n",
      "Iter: 15000\n",
      "Renyi divergence: [0.04803455]\n",
      "\n",
      "Iter: 16000\n",
      "Renyi divergence: [0.05018747]\n",
      "\n",
      "Iter: 17000\n",
      "Renyi divergence: [0.06018281]\n",
      "\n",
      "Iter: 18000\n",
      "Renyi divergence: [0.0674001]\n",
      "\n",
      "Iter: 19000\n",
      "Renyi divergence: [0.06629527]\n",
      "\n",
      "j= 1\n",
      "rho= 0.3\n",
      "Iteration: 0\n",
      "Iter: 0\n",
      "Renyi divergence: [-5.512382e-06]\n",
      "\n",
      "Iter: 1000\n",
      "Renyi divergence: [0.45554507]\n",
      "\n",
      "Iter: 2000\n",
      "Renyi divergence: [0.5080168]\n",
      "\n",
      "Iter: 3000\n",
      "Renyi divergence: [0.48336768]\n",
      "\n",
      "Iter: 4000\n",
      "Renyi divergence: [0.48992348]\n",
      "\n",
      "Iter: 5000\n",
      "Renyi divergence: [0.47656202]\n",
      "\n",
      "Iter: 6000\n",
      "Renyi divergence: [0.4823885]\n",
      "\n",
      "Iter: 7000\n",
      "Renyi divergence: [0.4799838]\n",
      "\n",
      "Iter: 8000\n",
      "Renyi divergence: [0.5040443]\n",
      "\n",
      "Iter: 9000\n",
      "Renyi divergence: [0.468184]\n",
      "\n",
      "Iter: 10000\n",
      "Renyi divergence: [0.5263424]\n",
      "\n",
      "Iter: 11000\n",
      "Renyi divergence: [0.4961772]\n",
      "\n",
      "Iter: 12000\n",
      "Renyi divergence: [0.52926064]\n",
      "\n",
      "Iter: 13000\n",
      "Renyi divergence: [0.550328]\n",
      "\n",
      "Iter: 14000\n",
      "Renyi divergence: [0.5120139]\n",
      "\n",
      "Iter: 15000\n",
      "Renyi divergence: [0.49935555]\n",
      "\n",
      "Iter: 16000\n",
      "Renyi divergence: [0.490592]\n",
      "\n",
      "Iter: 17000\n",
      "Renyi divergence: [0.4837947]\n",
      "\n",
      "Iter: 18000\n",
      "Renyi divergence: [0.5009656]\n",
      "\n",
      "Iter: 19000\n",
      "Renyi divergence: [0.51452017]\n",
      "\n",
      "Iteration: 1\n",
      "Iter: 0\n",
      "Renyi divergence: [-6.920891e-07]\n",
      "\n",
      "Iter: 1000\n",
      "Renyi divergence: [0.48671412]\n",
      "\n",
      "Iter: 2000\n",
      "Renyi divergence: [0.46554852]\n",
      "\n",
      "Iter: 3000\n",
      "Renyi divergence: [0.4717319]\n",
      "\n",
      "Iter: 4000\n",
      "Renyi divergence: [0.4622717]\n",
      "\n",
      "Iter: 5000\n",
      "Renyi divergence: [0.49948382]\n",
      "\n",
      "Iter: 6000\n",
      "Renyi divergence: [0.4873829]\n",
      "\n",
      "Iter: 7000\n",
      "Renyi divergence: [0.4756217]\n",
      "\n",
      "Iter: 8000\n",
      "Renyi divergence: [0.46411824]\n",
      "\n",
      "Iter: 9000\n",
      "Renyi divergence: [0.5125711]\n",
      "\n",
      "Iter: 10000\n",
      "Renyi divergence: [0.48346424]\n",
      "\n",
      "Iter: 11000\n",
      "Renyi divergence: [0.51217103]\n",
      "\n",
      "Iter: 12000\n",
      "Renyi divergence: [0.47340417]\n",
      "\n",
      "Iter: 13000\n",
      "Renyi divergence: [0.45387363]\n",
      "\n",
      "Iter: 14000\n",
      "Renyi divergence: [0.46457863]\n",
      "\n",
      "Iter: 15000\n",
      "Renyi divergence: [0.46619153]\n",
      "\n",
      "Iter: 16000\n",
      "Renyi divergence: [0.51953864]\n",
      "\n",
      "Iter: 17000\n",
      "Renyi divergence: [0.47175908]\n",
      "\n",
      "Iter: 18000\n",
      "Renyi divergence: [0.45933604]\n",
      "\n",
      "Iter: 19000\n",
      "Renyi divergence: [0.51007843]\n",
      "\n",
      "Iteration: 2\n",
      "Iter: 0\n",
      "Renyi divergence: [-1.5886035e-06]\n",
      "\n",
      "Iter: 1000\n",
      "Renyi divergence: [0.37487411]\n",
      "\n",
      "Iter: 2000\n",
      "Renyi divergence: [0.44486868]\n",
      "\n",
      "Iter: 3000\n",
      "Renyi divergence: [0.4914341]\n",
      "\n",
      "Iter: 4000\n",
      "Renyi divergence: [0.49004197]\n",
      "\n",
      "Iter: 5000\n",
      "Renyi divergence: [0.5174532]\n",
      "\n",
      "Iter: 6000\n",
      "Renyi divergence: [0.5115659]\n",
      "\n",
      "Iter: 7000\n",
      "Renyi divergence: [0.4561174]\n",
      "\n",
      "Iter: 8000\n",
      "Renyi divergence: [0.45722795]\n",
      "\n",
      "Iter: 9000\n",
      "Renyi divergence: [0.4940741]\n",
      "\n",
      "Iter: 10000\n",
      "Renyi divergence: [0.49810934]\n",
      "\n",
      "Iter: 11000\n",
      "Renyi divergence: [0.51652265]\n",
      "\n",
      "Iter: 12000\n",
      "Renyi divergence: [0.5125637]\n",
      "\n",
      "Iter: 13000\n",
      "Renyi divergence: [0.48978615]\n",
      "\n",
      "Iter: 14000\n",
      "Renyi divergence: [0.50078654]\n",
      "\n",
      "Iter: 15000\n",
      "Renyi divergence: [0.5250623]\n",
      "\n",
      "Iter: 16000\n",
      "Renyi divergence: [0.50543404]\n",
      "\n",
      "Iter: 17000\n",
      "Renyi divergence: [0.49148917]\n",
      "\n",
      "Iter: 18000\n",
      "Renyi divergence: [0.5449481]\n",
      "\n",
      "Iter: 19000\n",
      "Renyi divergence: [0.49525476]\n",
      "\n",
      "Iteration: 3\n",
      "Iter: 0\n",
      "Renyi divergence: [2.1200394e-06]\n",
      "\n",
      "Iter: 1000\n",
      "Renyi divergence: [0.4481697]\n",
      "\n",
      "Iter: 2000\n",
      "Renyi divergence: [0.49378753]\n",
      "\n",
      "Iter: 3000\n",
      "Renyi divergence: [0.46907187]\n",
      "\n",
      "Iter: 4000\n",
      "Renyi divergence: [0.48775768]\n",
      "\n",
      "Iter: 5000\n",
      "Renyi divergence: [0.45820594]\n",
      "\n",
      "Iter: 6000\n",
      "Renyi divergence: [0.46156836]\n",
      "\n",
      "Iter: 7000\n",
      "Renyi divergence: [0.51110077]\n",
      "\n",
      "Iter: 8000\n",
      "Renyi divergence: [0.45892406]\n",
      "\n",
      "Iter: 9000\n",
      "Renyi divergence: [0.45839596]\n",
      "\n",
      "Iter: 10000\n",
      "Renyi divergence: [0.49680448]\n",
      "\n",
      "Iter: 11000\n",
      "Renyi divergence: [0.5280758]\n",
      "\n",
      "Iter: 12000\n",
      "Renyi divergence: [0.45882225]\n",
      "\n",
      "Iter: 13000\n",
      "Renyi divergence: [0.4944079]\n",
      "\n",
      "Iter: 14000\n",
      "Renyi divergence: [0.5014241]\n",
      "\n",
      "Iter: 15000\n",
      "Renyi divergence: [0.5302429]\n",
      "\n",
      "Iter: 16000\n",
      "Renyi divergence: [0.49446893]\n",
      "\n",
      "Iter: 17000\n",
      "Renyi divergence: [0.48501992]\n",
      "\n",
      "Iter: 18000\n",
      "Renyi divergence: [0.5029378]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 19000\n",
      "Renyi divergence: [0.46324682]\n",
      "\n",
      "Iteration: 4\n",
      "Iter: 0\n",
      "Renyi divergence: [7.429626e-07]\n",
      "\n",
      "Iter: 1000\n",
      "Renyi divergence: [0.45968342]\n",
      "\n",
      "Iter: 2000\n",
      "Renyi divergence: [0.48030114]\n",
      "\n",
      "Iter: 3000\n",
      "Renyi divergence: [0.4931128]\n",
      "\n",
      "Iter: 4000\n",
      "Renyi divergence: [0.4654224]\n",
      "\n",
      "Iter: 5000\n",
      "Renyi divergence: [0.4725821]\n",
      "\n",
      "Iter: 6000\n",
      "Renyi divergence: [0.49355698]\n",
      "\n",
      "Iter: 7000\n",
      "Renyi divergence: [0.47008514]\n",
      "\n",
      "Iter: 8000\n",
      "Renyi divergence: [0.47316003]\n",
      "\n",
      "Iter: 9000\n",
      "Renyi divergence: [0.44152117]\n",
      "\n",
      "Iter: 10000\n",
      "Renyi divergence: [0.45607686]\n",
      "\n",
      "Iter: 11000\n",
      "Renyi divergence: [0.462914]\n",
      "\n",
      "Iter: 12000\n",
      "Renyi divergence: [0.47588634]\n",
      "\n",
      "Iter: 13000\n",
      "Renyi divergence: [0.49598098]\n",
      "\n",
      "Iter: 14000\n",
      "Renyi divergence: [0.50750613]\n",
      "\n",
      "Iter: 15000\n",
      "Renyi divergence: [0.4896989]\n",
      "\n",
      "Iter: 16000\n",
      "Renyi divergence: [0.46392083]\n",
      "\n",
      "Iter: 17000\n",
      "Renyi divergence: [0.50700307]\n",
      "\n",
      "Iter: 18000\n",
      "Renyi divergence: [0.49452972]\n",
      "\n",
      "Iter: 19000\n",
      "Renyi divergence: [0.4727428]\n",
      "\n",
      "j= 2\n",
      "rho= 0.5\n",
      "Iteration: 0\n",
      "Iter: 0\n",
      "Renyi divergence: [3.540772e-07]\n",
      "\n",
      "Iter: 1000\n",
      "Renyi divergence: [1.4445453]\n",
      "\n",
      "Iter: 2000\n",
      "Renyi divergence: [1.4971085]\n",
      "\n",
      "Iter: 3000\n",
      "Renyi divergence: [1.493372]\n",
      "\n",
      "Iter: 4000\n",
      "Renyi divergence: [1.579031]\n",
      "\n",
      "Iter: 5000\n",
      "Renyi divergence: [1.6037421]\n",
      "\n",
      "Iter: 6000\n",
      "Renyi divergence: [1.6109834]\n",
      "\n",
      "Iter: 7000\n",
      "Renyi divergence: [1.6709809]\n",
      "\n",
      "Iter: 8000\n",
      "Renyi divergence: [1.6171455]\n",
      "\n",
      "Iter: 9000\n",
      "Renyi divergence: [1.5996516]\n",
      "\n",
      "Iter: 10000\n",
      "Renyi divergence: [1.6418886]\n",
      "\n",
      "Iter: 11000\n",
      "Renyi divergence: [1.5734539]\n",
      "\n",
      "Iter: 12000\n",
      "Renyi divergence: [1.6872153]\n",
      "\n",
      "Iter: 13000\n",
      "Renyi divergence: [1.5245504]\n",
      "\n",
      "Iter: 14000\n",
      "Renyi divergence: [1.6155529]\n",
      "\n",
      "Iter: 15000\n",
      "Renyi divergence: [1.5976596]\n",
      "\n",
      "Iter: 16000\n",
      "Renyi divergence: [1.5534139]\n",
      "\n",
      "Iter: 17000\n",
      "Renyi divergence: [1.636775]\n",
      "\n",
      "Iter: 18000\n",
      "Renyi divergence: [1.5847898]\n",
      "\n",
      "Iter: 19000\n",
      "Renyi divergence: [1.6934474]\n",
      "\n",
      "Iteration: 1\n",
      "Iter: 0\n",
      "Renyi divergence: [3.812369e-06]\n",
      "\n",
      "Iter: 1000\n",
      "Renyi divergence: [1.2808743]\n",
      "\n",
      "Iter: 2000\n",
      "Renyi divergence: [1.4153776]\n",
      "\n",
      "Iter: 3000\n",
      "Renyi divergence: [1.4527123]\n",
      "\n",
      "Iter: 4000\n",
      "Renyi divergence: [1.4183102]\n",
      "\n",
      "Iter: 5000\n",
      "Renyi divergence: [1.6051974]\n",
      "\n",
      "Iter: 6000\n",
      "Renyi divergence: [1.521313]\n",
      "\n",
      "Iter: 7000\n",
      "Renyi divergence: [1.649508]\n",
      "\n",
      "Iter: 8000\n",
      "Renyi divergence: [1.5948093]\n",
      "\n",
      "Iter: 9000\n",
      "Renyi divergence: [1.6458168]\n",
      "\n",
      "Iter: 10000\n",
      "Renyi divergence: [1.5347295]\n",
      "\n",
      "Iter: 11000\n",
      "Renyi divergence: [1.5934658]\n",
      "\n",
      "Iter: 12000\n",
      "Renyi divergence: [1.5186949]\n",
      "\n",
      "Iter: 13000\n",
      "Renyi divergence: [1.6137447]\n",
      "\n",
      "Iter: 14000\n",
      "Renyi divergence: [1.6474903]\n",
      "\n",
      "Iter: 15000\n",
      "Renyi divergence: [1.619215]\n",
      "\n",
      "Iter: 16000\n",
      "Renyi divergence: [1.6116867]\n",
      "\n",
      "Iter: 17000\n",
      "Renyi divergence: [1.6211424]\n",
      "\n",
      "Iter: 18000\n",
      "Renyi divergence: [1.6290159]\n",
      "\n",
      "Iter: 19000\n",
      "Renyi divergence: [1.6531653]\n",
      "\n",
      "Iteration: 2\n",
      "Iter: 0\n",
      "Renyi divergence: [-2.274604e-05]\n",
      "\n",
      "Iter: 1000\n",
      "Renyi divergence: [1.438849]\n",
      "\n",
      "Iter: 2000\n",
      "Renyi divergence: [1.572283]\n",
      "\n",
      "Iter: 3000\n",
      "Renyi divergence: [1.4869678]\n",
      "\n",
      "Iter: 4000\n",
      "Renyi divergence: [1.6433926]\n",
      "\n",
      "Iter: 5000\n",
      "Renyi divergence: [1.6131144]\n",
      "\n",
      "Iter: 6000\n",
      "Renyi divergence: [1.6146665]\n",
      "\n",
      "Iter: 7000\n",
      "Renyi divergence: [1.6511688]\n",
      "\n",
      "Iter: 8000\n",
      "Renyi divergence: [1.5497932]\n",
      "\n",
      "Iter: 9000\n",
      "Renyi divergence: [1.6117244]\n",
      "\n",
      "Iter: 10000\n",
      "Renyi divergence: [1.5555305]\n",
      "\n",
      "Iter: 11000\n",
      "Renyi divergence: [1.6343393]\n",
      "\n",
      "Iter: 12000\n",
      "Renyi divergence: [1.630693]\n",
      "\n",
      "Iter: 13000\n",
      "Renyi divergence: [1.5529823]\n",
      "\n",
      "Iter: 14000\n",
      "Renyi divergence: [1.6391311]\n",
      "\n",
      "Iter: 15000\n",
      "Renyi divergence: [1.6126742]\n",
      "\n",
      "Iter: 16000\n",
      "Renyi divergence: [1.6652882]\n",
      "\n",
      "Iter: 17000\n",
      "Renyi divergence: [1.6350477]\n",
      "\n",
      "Iter: 18000\n",
      "Renyi divergence: [1.7035477]\n",
      "\n",
      "Iter: 19000\n",
      "Renyi divergence: [1.652564]\n",
      "\n",
      "Iteration: 3\n",
      "Iter: 0\n",
      "Renyi divergence: [-4.002475e-06]\n",
      "\n",
      "Iter: 1000\n",
      "Renyi divergence: [1.5081205]\n",
      "\n",
      "Iter: 2000\n",
      "Renyi divergence: [1.4919834]\n",
      "\n",
      "Iter: 3000\n",
      "Renyi divergence: [1.5201595]\n",
      "\n",
      "Iter: 4000\n",
      "Renyi divergence: [1.568831]\n",
      "\n",
      "Iter: 5000\n",
      "Renyi divergence: [1.5047462]\n",
      "\n",
      "Iter: 6000\n",
      "Renyi divergence: [1.5883965]\n",
      "\n",
      "Iter: 7000\n",
      "Renyi divergence: [1.5819306]\n",
      "\n",
      "Iter: 8000\n",
      "Renyi divergence: [1.6233144]\n",
      "\n",
      "Iter: 9000\n",
      "Renyi divergence: [1.6289823]\n",
      "\n",
      "Iter: 10000\n",
      "Renyi divergence: [1.529809]\n",
      "\n",
      "Iter: 11000\n",
      "Renyi divergence: [1.5695906]\n",
      "\n",
      "Iter: 12000\n",
      "Renyi divergence: [1.6474309]\n",
      "\n",
      "Iter: 13000\n",
      "Renyi divergence: [1.594121]\n",
      "\n",
      "Iter: 14000\n",
      "Renyi divergence: [1.653275]\n",
      "\n",
      "Iter: 15000\n",
      "Renyi divergence: [1.5708094]\n",
      "\n",
      "Iter: 16000\n",
      "Renyi divergence: [1.5041184]\n",
      "\n",
      "Iter: 17000\n",
      "Renyi divergence: [1.5741589]\n",
      "\n",
      "Iter: 18000\n",
      "Renyi divergence: [1.5843041]\n",
      "\n",
      "Iter: 19000\n",
      "Renyi divergence: [1.6359901]\n",
      "\n",
      "Iteration: 4\n",
      "Iter: 0\n",
      "Renyi divergence: [-6.93521e-06]\n",
      "\n",
      "Iter: 1000\n",
      "Renyi divergence: [1.4382381]\n",
      "\n",
      "Iter: 2000\n",
      "Renyi divergence: [1.5299203]\n",
      "\n",
      "Iter: 3000\n",
      "Renyi divergence: [1.6354208]\n",
      "\n",
      "Iter: 4000\n",
      "Renyi divergence: [1.6398821]\n",
      "\n",
      "Iter: 5000\n",
      "Renyi divergence: [1.4912701]\n",
      "\n",
      "Iter: 6000\n",
      "Renyi divergence: [1.5464563]\n",
      "\n",
      "Iter: 7000\n",
      "Renyi divergence: [1.6276445]\n",
      "\n",
      "Iter: 8000\n",
      "Renyi divergence: [1.5641379]\n",
      "\n",
      "Iter: 9000\n",
      "Renyi divergence: [1.6202884]\n",
      "\n",
      "Iter: 10000\n",
      "Renyi divergence: [1.6888509]\n",
      "\n",
      "Iter: 11000\n",
      "Renyi divergence: [1.7092485]\n",
      "\n",
      "Iter: 12000\n",
      "Renyi divergence: [1.7174778]\n",
      "\n",
      "Iter: 13000\n",
      "Renyi divergence: [1.5890288]\n",
      "\n",
      "Iter: 14000\n",
      "Renyi divergence: [1.5529366]\n",
      "\n",
      "Iter: 15000\n",
      "Renyi divergence: [1.7128887]\n",
      "\n",
      "Iter: 16000\n",
      "Renyi divergence: [1.5535941]\n",
      "\n",
      "Iter: 17000\n",
      "Renyi divergence: [1.6273823]\n",
      "\n",
      "Iter: 18000\n",
      "Renyi divergence: [1.6162868]\n",
      "\n",
      "Iter: 19000\n",
      "Renyi divergence: [1.5287924]\n",
      "\n",
      "j= 3\n",
      "rho= 0.7\n",
      "Iteration: 0\n",
      "Iter: 0\n",
      "Renyi divergence: [-1.4465768e-06]\n",
      "\n",
      "Iter: 1000\n",
      "Renyi divergence: [3.8632994]\n",
      "\n",
      "Iter: 2000\n",
      "Renyi divergence: [4.031707]\n",
      "\n",
      "Iter: 3000\n",
      "Renyi divergence: [3.9789653]\n",
      "\n",
      "Iter: 4000\n",
      "Renyi divergence: [3.8147693]\n",
      "\n",
      "Iter: 5000\n",
      "Renyi divergence: [4.0527477]\n",
      "\n",
      "Iter: 6000\n",
      "Renyi divergence: [3.8832603]\n",
      "\n",
      "Iter: 7000\n",
      "Renyi divergence: [4.1431327]\n",
      "\n",
      "Iter: 8000\n",
      "Renyi divergence: [4.0381436]\n",
      "\n",
      "Iter: 9000\n",
      "Renyi divergence: [4.0745096]\n",
      "\n",
      "Iter: 10000\n",
      "Renyi divergence: [4.008888]\n",
      "\n",
      "Iter: 11000\n",
      "Renyi divergence: [3.893641]\n",
      "\n",
      "Iter: 12000\n",
      "Renyi divergence: [4.02799]\n",
      "\n",
      "Iter: 13000\n",
      "Renyi divergence: [4.0805054]\n",
      "\n",
      "Iter: 14000\n",
      "Renyi divergence: [3.944459]\n",
      "\n",
      "Iter: 15000\n",
      "Renyi divergence: [4.080291]\n",
      "\n",
      "Iter: 16000\n",
      "Renyi divergence: [4.1389356]\n",
      "\n",
      "Iter: 17000\n",
      "Renyi divergence: [4.1366115]\n",
      "\n",
      "Iter: 18000\n",
      "Renyi divergence: [4.024523]\n",
      "\n",
      "Iter: 19000\n",
      "Renyi divergence: [4.384759]\n",
      "\n",
      "Iteration: 1\n",
      "Iter: 0\n",
      "Renyi divergence: [3.933499e-06]\n",
      "\n",
      "Iter: 1000\n",
      "Renyi divergence: [3.9436069]\n",
      "\n",
      "Iter: 2000\n",
      "Renyi divergence: [4.1270504]\n",
      "\n",
      "Iter: 3000\n",
      "Renyi divergence: [4.033505]\n",
      "\n",
      "Iter: 4000\n",
      "Renyi divergence: [4.115981]\n",
      "\n",
      "Iter: 5000\n",
      "Renyi divergence: [4.105036]\n",
      "\n",
      "Iter: 6000\n",
      "Renyi divergence: [4.07616]\n",
      "\n",
      "Iter: 7000\n",
      "Renyi divergence: [4.2533407]\n",
      "\n",
      "Iter: 8000\n",
      "Renyi divergence: [4.132566]\n",
      "\n",
      "Iter: 9000\n",
      "Renyi divergence: [4.1661777]\n",
      "\n",
      "Iter: 10000\n",
      "Renyi divergence: [4.26729]\n",
      "\n",
      "Iter: 11000\n",
      "Renyi divergence: [4.158325]\n",
      "\n",
      "Iter: 12000\n",
      "Renyi divergence: [4.1615295]\n",
      "\n",
      "Iter: 13000\n",
      "Renyi divergence: [4.2931137]\n",
      "\n",
      "Iter: 14000\n",
      "Renyi divergence: [4.1957226]\n",
      "\n",
      "Iter: 15000\n",
      "Renyi divergence: [4.0040255]\n",
      "\n",
      "Iter: 16000\n",
      "Renyi divergence: [4.1330357]\n",
      "\n",
      "Iter: 17000\n",
      "Renyi divergence: [4.1601267]\n",
      "\n",
      "Iter: 18000\n",
      "Renyi divergence: [4.01358]\n",
      "\n",
      "Iter: 19000\n",
      "Renyi divergence: [4.132687]\n",
      "\n",
      "Iteration: 2\n",
      "Iter: 0\n",
      "Renyi divergence: [1.5364145e-05]\n",
      "\n",
      "Iter: 1000\n",
      "Renyi divergence: [3.8862042]\n",
      "\n",
      "Iter: 2000\n",
      "Renyi divergence: [3.9176111]\n",
      "\n",
      "Iter: 3000\n",
      "Renyi divergence: [4.169608]\n",
      "\n",
      "Iter: 4000\n",
      "Renyi divergence: [4.0713425]\n",
      "\n",
      "Iter: 5000\n",
      "Renyi divergence: [3.888616]\n",
      "\n",
      "Iter: 6000\n",
      "Renyi divergence: [4.101276]\n",
      "\n",
      "Iter: 7000\n",
      "Renyi divergence: [4.1830544]\n",
      "\n",
      "Iter: 8000\n",
      "Renyi divergence: [3.9357858]\n",
      "\n",
      "Iter: 9000\n",
      "Renyi divergence: [4.165564]\n",
      "\n",
      "Iter: 10000\n",
      "Renyi divergence: [4.189943]\n",
      "\n",
      "Iter: 11000\n",
      "Renyi divergence: [4.0316243]\n",
      "\n",
      "Iter: 12000\n",
      "Renyi divergence: [4.2195754]\n",
      "\n",
      "Iter: 13000\n",
      "Renyi divergence: [4.0734234]\n",
      "\n",
      "Iter: 14000\n",
      "Renyi divergence: [4.1159678]\n",
      "\n",
      "Iter: 15000\n",
      "Renyi divergence: [3.9802098]\n",
      "\n",
      "Iter: 16000\n",
      "Renyi divergence: [4.24882]\n",
      "\n",
      "Iter: 17000\n",
      "Renyi divergence: [4.2184305]\n",
      "\n",
      "Iter: 18000\n",
      "Renyi divergence: [4.149933]\n",
      "\n",
      "Iter: 19000\n",
      "Renyi divergence: [4.0575557]\n",
      "\n",
      "Iteration: 3\n",
      "Iter: 0\n",
      "Renyi divergence: [-2.6972266e-06]\n",
      "\n",
      "Iter: 1000\n",
      "Renyi divergence: [3.0885644]\n",
      "\n",
      "Iter: 2000\n",
      "Renyi divergence: [3.4680438]\n",
      "\n",
      "Iter: 3000\n",
      "Renyi divergence: [3.8777199]\n",
      "\n",
      "Iter: 4000\n",
      "Renyi divergence: [3.6970677]\n",
      "\n",
      "Iter: 5000\n",
      "Renyi divergence: [3.6315913]\n",
      "\n",
      "Iter: 6000\n",
      "Renyi divergence: [3.7457633]\n",
      "\n",
      "Iter: 7000\n",
      "Renyi divergence: [3.6683464]\n",
      "\n",
      "Iter: 8000\n",
      "Renyi divergence: [3.7494526]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 9000\n",
      "Renyi divergence: [3.8419325]\n",
      "\n",
      "Iter: 10000\n",
      "Renyi divergence: [3.7928066]\n",
      "\n",
      "Iter: 11000\n",
      "Renyi divergence: [3.6408498]\n",
      "\n",
      "Iter: 12000\n",
      "Renyi divergence: [3.7099423]\n",
      "\n",
      "Iter: 13000\n",
      "Renyi divergence: [3.6169395]\n",
      "\n",
      "Iter: 14000\n",
      "Renyi divergence: [3.8747897]\n",
      "\n",
      "Iter: 15000\n",
      "Renyi divergence: [3.7861288]\n",
      "\n",
      "Iter: 16000\n",
      "Renyi divergence: [3.8009844]\n",
      "\n",
      "Iter: 17000\n",
      "Renyi divergence: [3.760405]\n",
      "\n",
      "Iter: 18000\n",
      "Renyi divergence: [3.7417936]\n",
      "\n",
      "Iter: 19000\n",
      "Renyi divergence: [4.2586546]\n",
      "\n",
      "Iteration: 4\n",
      "Iter: 0\n",
      "Renyi divergence: [-2.1327287e-07]\n",
      "\n",
      "Iter: 1000\n",
      "Renyi divergence: [3.8891804]\n",
      "\n",
      "Iter: 2000\n",
      "Renyi divergence: [4.100997]\n",
      "\n",
      "Iter: 3000\n",
      "Renyi divergence: [3.9897652]\n",
      "\n",
      "Iter: 4000\n",
      "Renyi divergence: [3.9786801]\n",
      "\n",
      "Iter: 5000\n",
      "Renyi divergence: [4.132096]\n",
      "\n",
      "Iter: 6000\n",
      "Renyi divergence: [4.187721]\n",
      "\n",
      "Iter: 7000\n",
      "Renyi divergence: [4.101253]\n",
      "\n",
      "Iter: 8000\n",
      "Renyi divergence: [4.215614]\n",
      "\n",
      "Iter: 9000\n",
      "Renyi divergence: [3.9490108]\n",
      "\n",
      "Iter: 10000\n",
      "Renyi divergence: [4.1552863]\n",
      "\n",
      "Iter: 11000\n",
      "Renyi divergence: [4.149747]\n",
      "\n",
      "Iter: 12000\n",
      "Renyi divergence: [3.9773197]\n",
      "\n",
      "Iter: 13000\n",
      "Renyi divergence: [4.2992067]\n",
      "\n",
      "Iter: 14000\n",
      "Renyi divergence: [4.2194448]\n",
      "\n",
      "Iter: 15000\n",
      "Renyi divergence: [4.0514197]\n",
      "\n",
      "Iter: 16000\n",
      "Renyi divergence: [4.320237]\n",
      "\n",
      "Iter: 17000\n",
      "Renyi divergence: [4.023375]\n",
      "\n",
      "Iter: 18000\n",
      "Renyi divergence: [4.0249753]\n",
      "\n",
      "Iter: 19000\n",
      "Renyi divergence: [4.2323666]\n",
      "\n",
      "j= 4\n",
      "rho= 0.9\n",
      "Iteration: 0\n",
      "Iter: 0\n",
      "Renyi divergence: [4.6391506e-07]\n",
      "\n",
      "Iter: 1000\n",
      "Renyi divergence: [10.543741]\n",
      "\n",
      "Iter: 2000\n",
      "Renyi divergence: [11.438785]\n",
      "\n",
      "Iter: 3000\n",
      "Renyi divergence: [11.586473]\n",
      "\n",
      "Iter: 4000\n",
      "Renyi divergence: [11.807674]\n",
      "\n",
      "Iter: 5000\n",
      "Renyi divergence: [11.5105715]\n",
      "\n",
      "Iter: 6000\n",
      "Renyi divergence: [11.783037]\n",
      "\n",
      "Iter: 7000\n",
      "Renyi divergence: [11.228878]\n",
      "\n",
      "Iter: 8000\n",
      "Renyi divergence: [11.346712]\n",
      "\n",
      "Iter: 9000\n",
      "Renyi divergence: [10.847862]\n",
      "\n",
      "Iter: 10000\n",
      "Renyi divergence: [11.660639]\n",
      "\n",
      "Iter: 11000\n",
      "Renyi divergence: [11.369639]\n",
      "\n",
      "Iter: 12000\n",
      "Renyi divergence: [11.386487]\n",
      "\n",
      "Iter: 13000\n",
      "Renyi divergence: [11.6273985]\n",
      "\n",
      "Iter: 14000\n",
      "Renyi divergence: [11.500724]\n",
      "\n",
      "Iter: 15000\n",
      "Renyi divergence: [11.887107]\n",
      "\n",
      "Iter: 16000\n",
      "Renyi divergence: [12.025946]\n",
      "\n",
      "Iter: 17000\n",
      "Renyi divergence: [12.182394]\n",
      "\n",
      "Iter: 18000\n",
      "Renyi divergence: [11.485118]\n",
      "\n",
      "Iter: 19000\n",
      "Renyi divergence: [11.718254]\n",
      "\n",
      "Iteration: 1\n",
      "Iter: 0\n",
      "Renyi divergence: [-7.595867e-06]\n",
      "\n",
      "Iter: 1000\n",
      "Renyi divergence: [10.622003]\n",
      "\n",
      "Iter: 2000\n",
      "Renyi divergence: [11.217056]\n",
      "\n",
      "Iter: 3000\n",
      "Renyi divergence: [11.367611]\n",
      "\n",
      "Iter: 4000\n",
      "Renyi divergence: [11.616886]\n",
      "\n",
      "Iter: 5000\n",
      "Renyi divergence: [11.459803]\n",
      "\n",
      "Iter: 6000\n",
      "Renyi divergence: [11.5330715]\n",
      "\n",
      "Iter: 7000\n",
      "Renyi divergence: [11.071966]\n",
      "\n",
      "Iter: 8000\n",
      "Renyi divergence: [11.456434]\n",
      "\n",
      "Iter: 9000\n",
      "Renyi divergence: [11.452511]\n",
      "\n",
      "Iter: 10000\n",
      "Renyi divergence: [11.467266]\n",
      "\n",
      "Iter: 11000\n",
      "Renyi divergence: [11.38817]\n",
      "\n",
      "Iter: 12000\n",
      "Renyi divergence: [11.8098545]\n",
      "\n",
      "Iter: 13000\n",
      "Renyi divergence: [11.214482]\n",
      "\n",
      "Iter: 14000\n",
      "Renyi divergence: [11.5536]\n",
      "\n",
      "Iter: 15000\n",
      "Renyi divergence: [11.534506]\n",
      "\n",
      "Iter: 16000\n",
      "Renyi divergence: [11.127218]\n",
      "\n",
      "Iter: 17000\n",
      "Renyi divergence: [11.675373]\n",
      "\n",
      "Iter: 18000\n",
      "Renyi divergence: [11.1206875]\n",
      "\n",
      "Iter: 19000\n",
      "Renyi divergence: [12.042969]\n",
      "\n",
      "Iteration: 2\n",
      "Iter: 0\n",
      "Renyi divergence: [1.0556774e-05]\n",
      "\n",
      "Iter: 1000\n",
      "Renyi divergence: [10.493055]\n",
      "\n",
      "Iter: 2000\n",
      "Renyi divergence: [11.242344]\n",
      "\n",
      "Iter: 3000\n",
      "Renyi divergence: [11.597242]\n",
      "\n",
      "Iter: 4000\n",
      "Renyi divergence: [10.69265]\n",
      "\n",
      "Iter: 5000\n",
      "Renyi divergence: [11.314413]\n",
      "\n",
      "Iter: 6000\n",
      "Renyi divergence: [11.683432]\n",
      "\n",
      "Iter: 7000\n",
      "Renyi divergence: [11.7288475]\n",
      "\n",
      "Iter: 8000\n",
      "Renyi divergence: [11.92671]\n",
      "\n",
      "Iter: 9000\n",
      "Renyi divergence: [11.487663]\n",
      "\n",
      "Iter: 10000\n",
      "Renyi divergence: [11.509596]\n",
      "\n",
      "Iter: 11000\n",
      "Renyi divergence: [11.449511]\n",
      "\n",
      "Iter: 12000\n",
      "Renyi divergence: [11.728216]\n",
      "\n",
      "Iter: 13000\n",
      "Renyi divergence: [11.49173]\n",
      "\n",
      "Iter: 14000\n",
      "Renyi divergence: [11.809408]\n",
      "\n",
      "Iter: 15000\n",
      "Renyi divergence: [11.795971]\n",
      "\n",
      "Iter: 16000\n",
      "Renyi divergence: [11.581575]\n",
      "\n",
      "Iter: 17000\n",
      "Renyi divergence: [12.163382]\n",
      "\n",
      "Iter: 18000\n",
      "Renyi divergence: [11.869364]\n",
      "\n",
      "Iter: 19000\n",
      "Renyi divergence: [12.294016]\n",
      "\n",
      "Iteration: 3\n",
      "Iter: 0\n",
      "Renyi divergence: [-9.127543e-06]\n",
      "\n",
      "Iter: 1000\n",
      "Renyi divergence: [10.6713505]\n",
      "\n",
      "Iter: 2000\n",
      "Renyi divergence: [10.747793]\n",
      "\n",
      "Iter: 3000\n",
      "Renyi divergence: [11.008976]\n",
      "\n",
      "Iter: 4000\n",
      "Renyi divergence: [11.083038]\n",
      "\n",
      "Iter: 5000\n",
      "Renyi divergence: [11.020331]\n",
      "\n",
      "Iter: 6000\n",
      "Renyi divergence: [11.7180805]\n",
      "\n",
      "Iter: 7000\n",
      "Renyi divergence: [11.694233]\n",
      "\n",
      "Iter: 8000\n",
      "Renyi divergence: [11.838984]\n",
      "\n",
      "Iter: 9000\n",
      "Renyi divergence: [12.032011]\n",
      "\n",
      "Iter: 10000\n",
      "Renyi divergence: [11.841578]\n",
      "\n",
      "Iter: 11000\n",
      "Renyi divergence: [11.827696]\n",
      "\n",
      "Iter: 12000\n",
      "Renyi divergence: [11.6537285]\n",
      "\n",
      "Iter: 13000\n",
      "Renyi divergence: [11.628038]\n",
      "\n",
      "Iter: 14000\n",
      "Renyi divergence: [11.559349]\n",
      "\n",
      "Iter: 15000\n",
      "Renyi divergence: [11.640089]\n",
      "\n",
      "Iter: 16000\n",
      "Renyi divergence: [11.253787]\n",
      "\n",
      "Iter: 17000\n",
      "Renyi divergence: [11.625265]\n",
      "\n",
      "Iter: 18000\n",
      "Renyi divergence: [11.915871]\n",
      "\n",
      "Iter: 19000\n",
      "Renyi divergence: [11.717585]\n",
      "\n",
      "Iteration: 4\n",
      "Iter: 0\n",
      "Renyi divergence: [-2.5185e-06]\n",
      "\n",
      "Iter: 1000\n",
      "Renyi divergence: [9.742975]\n",
      "\n",
      "Iter: 2000\n",
      "Renyi divergence: [11.268617]\n",
      "\n",
      "Iter: 3000\n",
      "Renyi divergence: [11.061977]\n",
      "\n",
      "Iter: 4000\n",
      "Renyi divergence: [11.865438]\n",
      "\n",
      "Iter: 5000\n",
      "Renyi divergence: [11.426756]\n",
      "\n",
      "Iter: 6000\n",
      "Renyi divergence: [11.227151]\n",
      "\n",
      "Iter: 7000\n",
      "Renyi divergence: [10.815564]\n",
      "\n",
      "Iter: 8000\n",
      "Renyi divergence: [11.221403]\n",
      "\n",
      "Iter: 9000\n",
      "Renyi divergence: [11.237701]\n",
      "\n",
      "Iter: 10000\n",
      "Renyi divergence: [11.6939125]\n",
      "\n",
      "Iter: 11000\n",
      "Renyi divergence: [11.483934]\n",
      "\n",
      "Iter: 12000\n",
      "Renyi divergence: [11.450895]\n",
      "\n",
      "Iter: 13000\n",
      "Renyi divergence: [11.653101]\n",
      "\n",
      "Iter: 14000\n",
      "Renyi divergence: [11.667526]\n",
      "\n",
      "Iter: 15000\n",
      "Renyi divergence: [12.141206]\n",
      "\n",
      "Iter: 16000\n",
      "Renyi divergence: [11.809896]\n",
      "\n",
      "Iter: 17000\n",
      "Renyi divergence: [11.970028]\n",
      "\n",
      "Iter: 18000\n",
      "Renyi divergence: [11.742487]\n",
      "\n",
      "Iter: 19000\n",
      "Renyi divergence: [12.039335]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# estimate Renyi divergence\n",
    "\n",
    "# Loop over #samples, then over iid iterations and then over training steps\n",
    "for j, rho in enumerate(rho_range): \n",
    "    \n",
    "    print('j=', j)\n",
    "    print('rho=', rho)\n",
    "    \n",
    "    # load data\n",
    "    fname = 'data/varying_rho_Sigma1_eye_2/d_' + str(d) + '/input_N' + str(N) + '_dim' + str(d) + '/gaussian_d_' + str(d) + '_'\n",
    "    data = scipy.io.loadmat(fname + 'data_'+str(rho)+'.mat')\n",
    "    x_ = np.array(data['x'])\n",
    "    y_ = np.array(data['y'])\n",
    "\n",
    "    params = scipy.io.loadmat(fname + 'params_'+str(rho)+'.mat')\n",
    "    alpha = np.array(params['alpha'])\n",
    "    No_alpha = alpha.shape[0]\n",
    "\n",
    "    RD_exact = np.array(params['RD_exact']) # contains exact for all alphas. In current datafiles, only one\n",
    "\n",
    "    \n",
    "    beta = lam*(1-alpha[0])  #   <----------- choose the first alpha value\n",
    "    gamma = lam*alpha[0]  #  <---------- choose the first alpha value\n",
    "    \n",
    "    #exact value for Renyi (estimated by integral computation)\n",
    "    RD_exact_rho[j] = RD_exact[0];\n",
    "    \n",
    "    # variational representation:\n",
    "    if beta == 0:\n",
    "        D_loss_real = -tf.reduce_mean(D_real)\n",
    "    else:\n",
    "        max_val = tf.reduce_max((-beta) * D_real)\n",
    "        D_loss_real = (1.0 / beta) * (tf.log(tf.reduce_mean(tf.exp((-beta) * D_real - max_val))) + max_val)\n",
    "\n",
    "    if gamma == 0:\n",
    "        D_loss_fake = tf.reduce_mean(D_fake)\n",
    "\n",
    "    else:\n",
    "        max_val = tf.reduce_max((gamma) * D_fake)\n",
    "        D_loss_fake = (1.0 / gamma) * (tf.log(tf.reduce_mean(tf.exp(gamma * D_fake - max_val))) + max_val)\n",
    "\n",
    "    D_loss = D_loss_real + D_loss_fake\n",
    "\n",
    "    # Gradient Penalty\n",
    "    alpha_gp = tf.random_uniform(shape=[mb_size,1], minval=0., maxval=1.)\n",
    "    interpolates = X + (alpha_gp*(Y - X)) \n",
    "    gradients = tf.gradients(discriminator(interpolates), [interpolates])[0]  \n",
    "    slopes = tf.sqrt(tf.reduce_sum(tf.square(gradients), reduction_indices=[1]))\n",
    "    gradient_penalty = tf.reduce_mean(tf.math.maximum(tf.zeros([slopes.shape[0]], dtype=tf.float32) ,(slopes-5.))**2)  # Lipschitz with K=5 \n",
    "\n",
    "    total_loss = D_loss + lam_gp*gradient_penalty\n",
    "\n",
    "    \n",
    "    D_solver = tf.train.AdamOptimizer(learning_rate=0.0005).minimize(total_loss, var_list=theta_D)\n",
    "\n",
    "    for iter in range(iteration):\n",
    "        print('Iteration: {}'.format(iter))\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        x = x_[np.random.randint(x_.shape[0], size=int(0.8*x_.shape[0])), :]\n",
    "        y = y_[np.random.randint(y_.shape[0], size=int(0.8*x_.shape[0])), :]\n",
    "\n",
    "        # initialize for plotting\n",
    "        i = 0\n",
    "        Pl_freq = 10\n",
    "        D_loss_plot = np.zeros(shape=((np.rint(steps / Pl_freq)).astype(int), 1))  # because we writeout every Pl_freq\n",
    "\n",
    "        for it in range(steps):\n",
    "            X_mb = x[np.random.randint(x.shape[0], size=mb_size), :]\n",
    "            Y_mb = y[np.random.randint(y.shape[0], size=mb_size), :]\n",
    "\n",
    "            _, D_loss_curr, D_tot_loss = sess.run([D_solver, D_loss, total_loss], feed_dict={X: X_mb, Y: Y_mb})\n",
    "\n",
    "            if it % Pl_freq == 0:\n",
    "                D_loss_plot[i] = D_loss_curr\n",
    "                i += 1\n",
    "\n",
    "            if it % SF == 0:\n",
    "                print('Iter: {}'.format(it))\n",
    "                print('Renyi divergence: {}'.format(-lam*D_loss_curr))\n",
    "                print()\n",
    "\n",
    "\n",
    "        D_loss_curr = sess.run(D_loss, feed_dict={X: x, Y: y})\n",
    "        D_loss_vals[j,iter] = -lam * D_loss_curr\n",
    "\n",
    " \n",
    "    # -----------------------------------------------------------------------------\n",
    "    # Plotting\n",
    "    # -----------------------------------------------------------------------------\n",
    "    if not os.path.exists('data/out_gaussian_Lip_plots/'):\n",
    "        os.makedirs('data/out_gaussian_Lip_plots/')\n",
    "\n",
    "    fig = plt.figure()\n",
    "    #plt.plot(D_loss_plot)\n",
    "    x_idx = np.linspace(0, steps, num=(np.rint(steps / Pl_freq)).astype(int))\n",
    "    plt.plot(x_idx, D_loss_plot)\n",
    "    plt.xlabel('steps')\n",
    "    plt.ylabel('D loss')\n",
    "    plt.savefig('data/out_gaussian_Lip_plots/cgan_Dloss' + str(j) + 'rho_' + str(rho) +'.png', bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29c1e5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.06768489  0.06294298  0.06431842  0.06464744  0.06270981]\n",
      " [ 0.51285553  0.49316168  0.50140214  0.49973631  0.49466968]\n",
      " [ 1.62027407  1.6040988   1.61174917  1.61577129  1.61236477]\n",
      " [ 4.11273813  4.18435574  4.12930059  4.11977959  4.15391111]\n",
      " [11.6809063  11.60157204 11.64017582 11.66044044 11.8524828 ]]\n"
     ]
    }
   ],
   "source": [
    "print(D_loss_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "expected-abraham",
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "\n",
    "with open('data/out_gaussian_Lip_plots/'+'lambda_'+str(lam)+ '_gp_' + str(lam_gp)+'_bs_'+str(mb_size)+'_nerd_'+str(rho)+'.csv', \"w\") as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n')\n",
    "    for val in D_loss_vals:\n",
    "        writer.writerow(val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "assisted-whale",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'divergence')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot RD vs rho\n",
    "#======================\n",
    "fig = plt.figure()\n",
    "plt.plot(rho_range, D_loss_vals[:,0])\n",
    "plt.xlabel('rho')\n",
    "plt.ylabel('divergence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fifty-tolerance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 14.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.set_title('NERD (Lipschitz)')\n",
    "ax1.boxplot(np.transpose(D_loss_vals[:,:]) , labels=[0.1, 0.3, 0.5, 0.7, 0.9], whis=2)\n",
    "ax1.plot(np.arange(1,len(rho_range)+1), RD_exact_rho[:],'r', 'LineWidth', 2 );\n",
    "plt.xlabel(r'$\\rho$')\n",
    "plt.ylabel(r'$\\mathcal{R}_{\\alpha}(Q||P)$')\n",
    "plt.ylim(0.0, 14.0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatal-watson",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('program terminated succesfully')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
